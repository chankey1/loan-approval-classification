# Loan Approval Classification - Group 3

This project was completed by the following contributors:
- Camden Hankey
- Zeel Amrutiya
- Siraaj Sumar
- Michael Okeke

## Navigation:
This repository is quite simple and straighforward. Our detailed steps and code and can be found in the index.ipynb file. Our data can be found in the data folder and any graphs or charts displayed in the code can be found in the images folder.


## Problem Statement:
We are trying to help banks and financial institutions qualify people of various socioeconomic backgrounds for personal loans. The process of granting loans is a fundamental exercise of the financial services industry, however there are still many inefficiencies throughout the process. Our project aims to optimize decision-making speed and accuracy while maintaining compliance standards. In accomplishing this by leveraging machine learning technologies, we hope to provide a cost-effective method to more accurately identify individuals who will be approved for loans, as well as reduce bias within the loan approval process through the reduction of human intervention and reviewing of applicant information.

## Data Science Process:

### 1. Dataset Description and Understanding
- [Link to our dataset](https://www.kaggle.com/datasets/vikramamin/bank-loan-approval-lr-dt-rf-and-auc/data)
- In this step we dive into our data and try to form and understanding of what shape our data takes and how we may be able to manipulate it to better suit it for modeling. 

### 2. Exploratory Data Analysis and Data Processing
- Perform analysis on data to help find any outliers, points of potential trouble, and to develop an deeper understanding of our data.
- Prepare our data for modeling by properly adjusting and scaling our data based on anything found in EDA.

### 3. Modeling
- Split our data into training and testing modules.
- Implement our first model (logistic regression) and iterate through parameter tuning and resampling our data.
- Implement our second model (decision tree classifier) and iterate through parameter tuning and resampling to get better performance.
- Implement a third model (random forest classifier) and evaluate based on metrics.
